{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIT-S-CNN BSS Eval example notebook\n",
    "\n",
    "This notebook contains an example of computing SDR, SIR, and SAR improvements on signals separated using Lab41's model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generic imports\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Plotting imports\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "from matplotlib import pyplot as plt\n",
    "fig_size = [0,0]\n",
    "fig_size[0] = 8\n",
    "fig_size[1] = 4\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "# Import Lab41's separation model\n",
    "from magnolia.dnnseparate.pit import PITModel\n",
    "\n",
    "# Import utilities for using the model\n",
    "from magnolia.features.hdf5_iterator import SplitsIterator\n",
    "from magnolia.features.supervised_iterator import SupervisedMixer\n",
    "from magnolia.utils.clustering_utils import clustering_separate, preprocess_signal\n",
    "from magnolia.features.mixer import FeatureMixer\n",
    "from magnolia.features.spectral_features import istft, scale_spectrogram\n",
    "from magnolia.utils.postprocessing import reconstruct\n",
    "from magnolia.features.data_preprocessing import undo_preemphasis\n",
    "from magnolia.utils.bss_eval import bss_eval_sources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "libritest = \"** Path to librispeech test hdf5 **\"\n",
    "model_path = \"** Path to model checkpoint **\"\n",
    "libritrain = \"** path to LibriSpeech train hdf5 **\"\n",
    "female_speakers = '** path to list of female speakers in train set (available in repo) **'\n",
    "male_speakers = '** path to list of male speakers in train set (in repo) **'\n",
    "female_speakers_test = 'data/librispeech/authors/test-clean-M.txt'\n",
    "male_speakers_test = 'data/librispeech/authors/test-clean-M.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "    fft_size    : Number of samples in the fft window\n",
    "    overlap     : Amount of overlap in the fft windows\n",
    "    sample_rate : Number of samples per second in the input signals\n",
    "    numsources  : Number of sources\n",
    "    datashape   : (Number of time steps, nubmer of frequency bins)\n",
    "    preemp_coef : Preemphasis coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fft_size = 512\n",
    "overlap = 0.0256\n",
    "sample_rate = 10000\n",
    "numsources = 2\n",
    "datashape = (51, fft_size//2 + 1)\n",
    "preemp_coef = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and load an instance of Lab41's source separation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = PITModel(method='pit-s-cnn', num_steps=datashape[0], num_freq_bins=datashape[1], num_srcs=numsources)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "model.load(model_path, sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some helper functions for evaluating BSS metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bss_eval_sample(mixer, num_sources):\n",
    "    \"\"\"\n",
    "    Function to generate a sample from mixer and evaluate BSS metrics on it\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate a sample\n",
    "    data = next(mixer)\n",
    "    \n",
    "    # Get the waveforms for the mixed signal and the true sources\n",
    "    mixes = [reconstruct(data[0], data[0], sample_rate, None, overlap, preemphasis=preemp_coef)] * num_sources\n",
    "    sources = [reconstruct(src, src, sample_rate, None, overlap, preemphasis=preemp_coef) for metadata, src in data[1:]]\n",
    "    \n",
    "    # Stack the input mix and the true sources into arrays\n",
    "    input_mix = np.stack(mixes)\n",
    "    reference_sources = np.stack(sources)\n",
    "    \n",
    "    # Use the model to separate the signal into the desired number of sources\n",
    "    spec = data[0]\n",
    "    spec_mag, spec_phase = scale_spectrogram(spec)\n",
    "    sources_spec = model.separate(spec_mag, sess)\n",
    "    estimated_sources = np.stack([reconstruct(x, spec, sample_rate, None, overlap, \n",
    "                                     square=True, preemphasis=preemp_coef) for x in sources_spec])\n",
    "    \n",
    "    # Compute the SDR, SIR, SAR of the input mixes\n",
    "    do_nothing = bss_eval_sources(reference_sources, input_mix)\n",
    "    \n",
    "    # Compute the SDR, SIR, SAR of the separated sources\n",
    "    do_something = bss_eval_sources(reference_sources, estimated_sources)\n",
    "    \n",
    "    # Compute the SDR, SIR, SAR improvement due to separation\n",
    "    sdr = do_something[0] - do_nothing[0]\n",
    "    sir = do_something[1] - do_nothing[1]\n",
    "    sar = do_something[2] - do_nothing[2]\n",
    "    \n",
    "    return {'SDR': sdr, 'SIR': sir, 'SAR': sar}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of in set BSS metrics\n",
    "\n",
    "This section shows the evaluation of SDR, SIR, and SAR on mixtures of speakers that are in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the speaker keys corresponding to F and M speakers in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(female_speakers,'r') as speakers:\n",
    "    keys = speakers.read().splitlines()\n",
    "    speaker_keys = keys[:]\n",
    "    in_set_F = keys[:]\n",
    "    \n",
    "with open(male_speakers,'r') as speakers:\n",
    "    keys = speakers.read().splitlines()\n",
    "    speaker_keys += keys\n",
    "    in_set_M = keys[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mixers for in set FF, FM, MM, and all speaker mixes.\n",
    "\n",
    "The splits used in creating each SplitsIterator should be the same as the ones used in training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an iterator over the male speakers in set and set the active split to the test split\n",
    "maleiter = SplitsIterator([0.8,0.1,0.1], libritrain, speaker_keys=in_set_M, shape=(150,fft_size//2+1), return_key=True)\n",
    "maleiter.set_split(2)\n",
    "\n",
    "# Create an iterator over the female speakers in set and set the active split to the test split\n",
    "femaleiter = SplitsIterator([0.8,0.1,0.1], libritrain, speaker_keys=in_set_F, shape=(150,fft_size//2+1), return_key=True)\n",
    "femaleiter.set_split(2)\n",
    "\n",
    "# Create mixers for each type of possible speaker mixes\n",
    "MMmixer = SupervisedMixer([maleiter,maleiter], shape=(150,fft_size//2+1), \n",
    "                          mix_method='add', diffseed=True)\n",
    "FFmixer = SupervisedMixer([femaleiter,femaleiter], shape=(150,fft_size//2+1), \n",
    "                          mix_method='add', diffseed=True)\n",
    "MFmixer = SupervisedMixer([maleiter,femaleiter], shape=(150,fft_size//2+1), \n",
    "                          mix_method='add', diffseed=True)\n",
    "FMmixer = SupervisedMixer([femaleiter,maleiter], shape=(150,fft_size//2+1), \n",
    "                          mix_method='add', diffseed=True)\n",
    "mixers = [MMmixer, FFmixer, MFmixer, FMmixer]\n",
    "\n",
    "# Some book keeping in preparation for evaluating on samples from the mixers\n",
    "mixerdesc = ['MM','FF','MF','FM']\n",
    "mixersSDR = [[],[],[],[]]\n",
    "mixersSIR = [[],[],[],[]]\n",
    "mixersSAR = [[],[],[],[]]\n",
    "    \n",
    "i=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate BSS metrics on 500 samples from each mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of samples to evaluate\n",
    "num_samples = 500\n",
    "\n",
    "# Get the starting i\n",
    "try:\n",
    "    starti = i\n",
    "except:\n",
    "    starti = 0\n",
    "\n",
    "# Iterate over samples, computing BSS metrics for samples from each mixer\n",
    "for i in range(starti, num_samples):\n",
    "    for j,mixer in enumerate(mixers):\n",
    "        \n",
    "        # Compute SDR, SIR, SAR for this mixer\n",
    "        evals = bss_eval_sample(mixer, 2)\n",
    "        \n",
    "        # Store the results\n",
    "        mixersSDR[j].append( 1/(2)*(evals['SDR'][0] + evals['SDR'][1]) )\n",
    "        mixersSIR[j].append( 1/(2)*(evals['SIR'][0] + evals['SIR'][1]) )\n",
    "        mixersSAR[j].append( 1/(2)*(evals['SAR'][0] + evals['SAR'][1]) )\n",
    "        \n",
    "        # Compute the mean SDR, SIR, SAR\n",
    "        MMSDR = np.mean(mixersSDR[0])\n",
    "        FFSDR = np.mean(mixersSDR[1])\n",
    "        MFSDR = np.mean(mixersSDR[2])\n",
    "        FMSDR = np.mean(mixersSDR[3])\n",
    "\n",
    "    # Clear the display and show the progress so far\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    print(str(i)+':' + \n",
    "                 '  MM: ' + str(MMSDR) +\n",
    "                 ', FF: ' + str(FFSDR) +\n",
    "                 ', MF: ' + str((MFSDR+FMSDR)/2) +\n",
    "                 ', All: '+ str((MMSDR+FMSDR+MFSDR+FFSDR)/4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of out of set BSS metrics\n",
    "\n",
    "This section shows the evaluation of SDR, SIR, SAR on mixtures of speakers that were not in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the speaker keys for F and M speakers from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(female_speakers_test,'r') as speakers:\n",
    "    out_set_F = speakers.read().splitlines()\n",
    "\n",
    "with open(male_speakers_test,'r') as speakers:\n",
    "    out_set_M = speakers.read().splitlines()\n",
    "    \n",
    "all_speakers = out_set_F + out_set_M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mixers for out of set FF FM MM, all, speaker mixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make an iterator over female speakers\n",
    "Fiterator = SplitsIterator([1], libritest, speaker_keys=out_set_F, shape=datashape, return_key=True)\n",
    "Fiterator.set_split(0)\n",
    "\n",
    "# Make an iterator over male speakers\n",
    "Miterator = SplitsIterator([1], libritest, speaker_keys=out_set_M, shape=datashape, return_key=True)\n",
    "Miterator.set_split(0)\n",
    "\n",
    "# Make an iterator over all speakers\n",
    "Aiterator = SplitsIterator([1], libritest, speaker_keys=all_speakers, shape=datashape, return_key=True)\n",
    "\n",
    "\n",
    "# Create mixers for each combination of speakers\n",
    "outsetFFmixer = SupervisedMixer([Fiterator,Fiterator], shape=datashape, \n",
    "                        mix_method='add', diffseed=True)\n",
    "outsetFMmixer = SupervisedMixer([Fiterator,Miterator], shape=datashape, \n",
    "                        mix_method='add', diffseed=True)\n",
    "outsetMMmixer = SupervisedMixer([Miterator,Miterator], shape=datashape, \n",
    "                        mix_method='add', diffseed=True)\n",
    "outsetAAmixer = SupervisedMixer([Aiterator,Aiterator], shape=datashape, \n",
    "                        mix_method='add', diffseed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the BSS metrics for out of set speakers works as above for in set speakers using these mixers."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [magnolia3-cpu]",
   "language": "python",
   "name": "Python [magnolia3-cpu]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
