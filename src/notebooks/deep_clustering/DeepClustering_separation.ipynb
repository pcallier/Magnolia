{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separation of speakers using the deep clustering model\n",
    "\n",
    "This notebook contains an example of loading an already trained version of the deep clustering source separation model.  It also shows how to use the loaded model to separate individual speakers from an example waveform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generic imports\n",
    "import numpy as np\n",
    "\n",
    "# Imports to play audio\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Import the deep clustering separation model\n",
    "from magnolia.dnnseparate.deep_clustering_model import DeepClusteringModel\n",
    "\n",
    "# Import utilities for using the model\n",
    "from magnolia.utils.clustering_utils import clustering_separate\n",
    "from magnolia.features.mixer import FeatureMixer\n",
    "from magnolia.features.spectral_features import istft\n",
    "from magnolia.features.data_preprocessing import undo_preemphasis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "    fft_size    : Number of samples in the fft window\n",
    "    overlap     : Amount of overlap in the fft windows\n",
    "    sample_rate : Number of samples per second in the input signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fft_size = 512\n",
    "overlap = 0.0256\n",
    "sample_rate = 1e4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and load a pretrained instance of the deep clustering model\n",
    "\n",
    "Here an untrained model instance is created, and the pretrained weights are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DeepClusteringModel()\n",
    "\n",
    "model.load(\"Path to saved model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example separation process\n",
    "\n",
    "Samples can be generated from the dev set for qualitatively evaluating the perfomance of the model and to test the separation process.  For this example, a sample will be generated, converted to a raw waveform, and then separated into two sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a mixer for recordings from the dev set\n",
    "libridev = \"Path to dev set\"\n",
    "long_mixer = FeatureMixer([libridev,libridev], shape=(200,None)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an example from the mixer and convert it back into a waveform via the istdt function and undo the preemphasis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = next(long_mixer)\n",
    "spec = data[0]\n",
    "signal = istft(spec,sample_rate,None,overlap,two_sided=False,fft_size=512)\n",
    "signal = undo_preemphasis(signal)\n",
    "\n",
    "Audio(signal,rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model and the clustering_separate function to separate the signal waveform into sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sources = clustering_separate(signal,sample_rate,model,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listen to the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Audio(sources[0], rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Audio(sources[1], rate=sample_rate)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "tensorflow1.1",
   "language": "python",
   "name": "tf1.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
