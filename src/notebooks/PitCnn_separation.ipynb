{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separation of speakers using PIT-S-CNN\n",
    "\n",
    "This notebook contains an example of loading an already trained version of the PIT-S-CNN source separation model.  It also shows how to use the loaded model to separate individual speakers from an example waveform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Imports to play audio\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Import Lab41's separation model\n",
    "from magnolia.dnnseparate.pit import PITModel\n",
    "\n",
    "# Import utilities for using the model\n",
    "from magnolia.utils.clustering_utils import clustering_separate, preprocess_signal\n",
    "from magnolia.features.mixer import FeatureMixer\n",
    "from magnolia.features.spectral_features import istft, scale_spectrogram\n",
    "from magnolia.utils.postprocessing import reconstruct\n",
    "from magnolia.features.data_preprocessing import undo_preemphasis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libridev = \"** Path to librispeech dev hdf5 **\"\n",
    "model_path = \"** Path to model checkpoint **\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "    fft_size    : Number of samples in the fft window\n",
    "    overlap     : Amount of overlap in the fft windows\n",
    "    sample_rate : Number of samples per second in the input signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_size = 512\n",
    "overlap = 0.0256\n",
    "sample_rate = 10000\n",
    "numsources = 2\n",
    "datashape = (51, fft_size//2 + 1)\n",
    "preemp_coef = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and load a pretrained instance of PIT-S-CNN\n",
    "\n",
    "Here an untrained model instance is created, and the pretrained weights are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = PITModel(method='pit-s-cnn', num_steps=datashape[0], num_freq_bins=datashape[1], num_srcs=numsources)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "model.load(model_path, sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example separation process\n",
    "\n",
    "Samples can be generated from the dev set for qualitatively evaluating the perfomance of the model and to test the separation process.  For this example, a sample will be generated, converted to a raw waveform, and then separated into two sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mixer for recordings from the dev set\n",
    "long_mixer = FeatureMixer([libridev,libridev], shape=(200,None)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an example from the mixer and convert it back into a waveform via the istdt function and undo the preemphasis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(long_mixer)\n",
    "spec = data[0]\n",
    "spec_mag, spec_phase = scale_spectrogram(spec)\n",
    "signal = istft(spec,sample_rate,None,overlap,two_sided=False,fft_size=512)\n",
    "signal = undo_preemphasis(signal)\n",
    "\n",
    "Audio(signal,rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model's separate function to separate the signal waveform into sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_spec = model.separate(spec_mag, sess)\n",
    "sources = [reconstruct(x, spec, sample_rate, None, overlap, square=True, preemphasis=preemp_coef) for x in sources_spec]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listen to the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sources[0], rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sources[1], rate=sample_rate)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [magnolia3-cpu]",
   "language": "python",
   "name": "Python [magnolia3-cpu]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
